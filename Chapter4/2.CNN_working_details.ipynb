{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from torch.optim import SGD, Adam\n",
    "from torchvision import datasets\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor([[[[1,2,3,4],[2,3,4,5], [5,6,7,8],[1,3,4,5]]],\n",
    "                        [[[-1,2,3,-4],[2,-3,4,5], [-5,6,-7,8],[-1,-3,-4,-5]]]\n",
    "                       ]).to(device).float()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input shape is **N×C×H×W** such that  \n",
    "\n",
    "**N:** Batch size  \n",
    "**C:** Channel numbers  \n",
    "**H:** Height  \n",
    "**W:** Width  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= X_train.max() # Scale to the range [-1, 1]\n",
    "y_train = torch.tensor([0, 1]).to(device).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 1, kernel_size=3),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(1, 1),\n",
    "        nn.Sigmoid()\n",
    "    ).to(device)\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    return model, loss_function, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 1, 2, 2]             10\n",
      "├─MaxPool2d: 1-2                         [-1, 1, 1, 1]             --\n",
      "├─ReLU: 1-3                              [-1, 1, 1, 1]             --\n",
      "├─Flatten: 1-4                           [-1, 1]                   --\n",
      "├─Linear: 1-5                            [-1, 1]                   2\n",
      "├─Sigmoid: 1-6                           [-1, 1]                   --\n",
      "==========================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model, loss_function, optimizer = get_model()\n",
    "summary(model, X_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conv2d has 10 parameters**: 3×3 = 9 weights + 1 bias.  \n",
    "**MaxPool2d, ReLU, Flattern do not have any parameters**: Because these are just operations that we perform on top of the output of convolution layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(X, y, model, optimizer, loss_function):\n",
    "    model.train()\n",
    "    prediction = model(X)\n",
    "    batch_loss = loss_function(prediction.squeeze(0), y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(TensorDataset(X_train, y_train))\n",
    "\n",
    "for epoch in range(2000):\n",
    "    for batch in train_dataloader:\n",
    "        X, y = batch\n",
    "        batch_loss = train_batch(X, y, model, optimizer, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5310]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward propagating the output\n",
    "Note that **We don't need to perform the following steps in a real-world scenario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1)),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " ReLU(),\n",
       " Flatten(start_dim=1, end_dim=-1),\n",
       " Linear(in_features=1, out_features=1, bias=True),\n",
       " Sigmoid()]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the various layers of the model\n",
    "list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cnn_w, cnn_b), (linear_w, linear_b) = [(layer.weight.data, layer.bias.data) for layer in list(model.children())\n",
    "                                        if hasattr(layer, 'weight')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_im, w_im = X_train.shape[2:] # 0 is for batch size and 1 is for channel numbers\n",
    "h_conv, w_conv  = cnn_w.shape[2:]\n",
    "sumprod = torch.zeros((h_im - h_conv + 1, w_im - w_conv + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension of `sumprod` comes from the following formula:\n",
    "$$n_{out} = [\\frac{n_{in} + 2p - k}{s}] + 1$$\n",
    "$n_{in}$: Number of input features  \n",
    "$n_{out}$: Number of output features  \n",
    "**k**: Convolution kernel size  \n",
    "**p**: Convolution padding size  \n",
    "**s**: Convolution stride size  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2691, -0.3445],\n",
       "        [-0.4178, -0.4846]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling sumprod by convolving the filter accross the input and summing up the filter bias term\n",
    "\n",
    "kernel_size = 3\n",
    "\n",
    "for i in range(h_im - h_conv + 1):\n",
    "    for j in range(w_im - w_conv + 1):\n",
    "        img_subset = X_train[0, 0, i:(i+kernel_size), j:(j+kernel_size)]\n",
    "        model_filter = cnn_w.reshape(3, 3)\n",
    "        val = torch.sum(img_subset * model_filter) + cnn_b\n",
    "        sumprod[i, j] = val\n",
    "\n",
    "sumprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ReLU\n",
    "sumprod.clamp_min_(0)\n",
    "\n",
    "sumprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_layer_output = torch.max(sumprod) # Since it's just 2×2\n",
    "pooling_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_output_value = pooling_layer_output * linear_w * linear_b\n",
    "intermediate_output_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass the output through sigmoid\n",
    "torch.sigmoid(intermediate_output_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
